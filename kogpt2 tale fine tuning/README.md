# 동화 데이터 학습 시켜보기

## 데이터
- **출처 1**: [네이버 블로그](https://blog.naver.com/osy2201/221179543994)

## 언어 모델 평가 지표
- **Perplexity**  
  언어 모델의 정확성을 평가하기 위한 지표. 값이 낮을수록 모델의 예측 능력이 우수함.  
  [Perplexity 자세히 보기](https://rfriend.tistory.com/851)

---

## 모델
- **모델명**: `skt/kogpt2-base-v2`
- [티스토리 블로그](https://gyong0117.tistory.com/50)

### 학습 전 텍스트 생성 예시
```plaintext
성냥팔이 소녀는 추운 날씨에 성냥을 팔기 위해 나섰어요!
그런데 그게 웬일입니까?
아니, 저도 모르게, 아저씨가 갑자기 뭔가 이상한 소리를 하더군요.
"아, 아니야. 이거 뭐예요."
성냥 파는 가게의 주인은 아주머니에게 이렇게 말했습니다.
'뭐야, 이런 거 있잖소.'
그러자 손님은 깜짝 놀라며 고개를 끄덕였어요.
그리고 잠시 후, 주인 할머니께서 말씀하셨지요.
'이건 정말 장난이야! 네놈들이 왜 그렇게 많은 돈을 벌었지? 너희들은 모두 다 도둑질하고 있어."
 ```

### 학습 후 텍스트 생성 예시
```plaintext
성냥팔이 소녀는 추운 날씨에 성냥을 팔기 위해 나섰어요원문소년의 할머니 집을 지나갈 때면 항상 이렇게 말하곤 했어요.
할머니, 이게 다 무슨 일이랍니까?
그럼요,라며 소년은 대답했어요.
하지만 그건 네가 한 번 더 외출할 때마다 하는 소리였지요.
너를 따뜻하게 해주마.
그래서 그녀는 밖으로 나가 땔감을 구하러 숲으로 들어갔답니다.
숲에서 가장 가까이에 있는 오두막집에 도착해 보니 거기엔 모두들 잠들어 있었죠.
오두막은 온통 금으로 만들어져 있었고 벽난로 위에는 은과 금을 상징하는 글씨체로 된 큰 홀 하나가 서 있었는데, 아무도 눈을
 ```

---

## 학습 지표 결과

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.138207</td>
      <td>3.968688</td>
      <td>52.915085</td>
      <td>00:53</td>
    </tr>
    <tr>
      <td>1</td>
      <td>3.863968</td>
      <td>3.885596</td>
      <td>48.695957</td>
      <td>00:52</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.564215</td>
      <td>3.876297</td>
      <td>48.245255</td>
      <td>00:53</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.270773</td>
      <td>3.906835</td>
      <td>49.741276</td>
      <td>00:52</td>
    </tr>
    <tr>
      <td>4</td>
      <td>3.017443</td>
      <td>3.930007</td>
      <td>50.907345</td>
      <td>00:52</td>
    </tr>
    <tr>
      <td>5</td>
      <td>2.798434</td>
      <td>3.955456</td>
      <td>52.219528</td>
      <td>00:52</td>
    </tr>
    <tr>
      <td>6</td>
      <td>2.622091</td>
      <td>3.986397</td>
      <td>53.860493</td>
      <td>00:53</td>
    </tr>
    <tr>
      <td>7</td>
      <td>2.486773</td>
      <td>3.995488</td>
      <td>54.352367</td>
      <td>00:53</td>
    </tr>
    <tr>
      <td>8</td>
      <td>2.398636</td>
      <td>3.995259</td>
      <td>54.339890</td>
      <td>00:53</td>
    </tr>
    <tr>
      <td>9</td>
      <td>2.359066</td>
      <td>3.992496</td>
      <td>54.189991</td>
      <td>00:53</td>
    </tr>
  </tbody>
</table>

![image](https://github.com/user-attachments/assets/9850d5e2-853c-43a0-988d-e67eb7f33146)

---
## 분석 및 결론
1. Train Loss가 꾸준히 감소하는 반면, Validation Loss는 3 Epoch 이후 증가 경향을 보임.
→ Overfitting 가능성 존재.

2. Perplexity는 초반에 감소하나, 후반부에는 다시 증가.
→ 학습 데이터의 품질 문제 또는 학습 조기 종료 필요.

3. 학습 후 결과 텍스트에서 문맥적 자연스러움이 부족.
→ 데이터 추가 확보 또는 전처리 필요.

개선 방향
데이터 전처리 강화: 문맥 및 구문 분석 추가 적용.
학습 파라미터 조정: 학습률, 배치 크기 등 세부 튜닝.(시간 날 때 꼬옥 해보자)
